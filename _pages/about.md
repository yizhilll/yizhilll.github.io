---
layout: about
title: home
permalink: /
subtitle: <a href='#'>üçö</a>. # Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Kilburn Building,</p>
    <p>Oxford Rd,</p>
    <p>Manchester M13 9PL, UK</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

<meta name="google-site-verification" content="S4kbKtEbks2C_vUp5k0RsyUsqnr4iLwD6euFRIdAoQY" />

<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

I am currently a Computer Science PhD student funded by the University of Manchester, supervised by [Prof. Chenghua Lin](https://chenghualin.wordpress.com/). I am also a co-founder of the [Multimodal Art Projection (M-A-P)](https://m-a-p.ai) research community, which aims to drive open-source academia-level research to cutting-edge level as the industry. I've collaborated with [Dr. Jie Fu](https://bigaidream.github.io/) and had a lot fun.  

---
#### Research

My current research study involves post-training of LLMs and multi-modal alignment, and the research questions including:

* How to build an effective and robust self-evolved framework for LLMs with data synthesis (maingly during post-trianing)? Deriving important sub questions:
  1. What is a good criteria for evaluating what the model acutally understand?
  2. How to verify the quality of the generated contents, considering domain knowledge and general metrics?
* How to unifiy the understanding and generation of vision-langauge models?
* The paradgim of aligning model among the text, vision and audio modalities.

Before the LLM era, my research interests could be concluded as these topics: language model evaluation, information retrieval, fairness in NLP, music modelling, and general topics natural language modelling.
More recent and detailed topics can be referred to my [publication pages](https://yizhilll.github.io/publications/).


---
#### Passed Experience

* Intenrned at [J.P. Morgan Artificial Intelligence Research](https://www.jpmorgan.com/technology/artificial-intelligence).
* I previously worked as a research assistant at Tsinghua NLP Lab with [Prof. Zhiyuan Liu](https://nlp.csai.tsinghua.edu.cn/~lzy/).


Academic Service: reviewer at ACL, EACL, EMNLP, INLG, ISMIR, ICLR, ICASSP, NeurIPS.
